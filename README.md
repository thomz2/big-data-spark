
# ‚ö° Big Data - Apache Spark

Aplicando ci√™ncia de dados em cima de grandes volumes de dados atrav√©s do paradigma de divis√£o e conquista com Apache Spark




## üíª Ambiente

Fizemos nosso trabalho usando dois ambientes distintos: um ambiente local e o Google Colab. Optamos por essa abordagem pois n√£o tinhamos recursos suficientes para o processamento de dados dos tweets.

No ambiente local, configuramos nosso pr√≥prio ambiente de desenvolvimento Spark em nossas m√°quinas. Usamos esse ambiente principalmente para a an√°lise das reviews, pois pod√≠amos acessar facilmente os conjuntos de dados locais e executar nossos scripts Spark diretamente em nossas m√°quinas.

Por outro lado, usamos o Google Colab para a campanha pol√≠tica. Optamos por essa plataforma porque ela oferece recursos computacionais poderosos e uma integra√ß√£o f√°cil com o Spark. Como a campanha pol√≠tica envolvia o processamento de grandes volumes de dados em escala, o ambiente do Google Colab nos proporcionou os recursos necess√°rios para lidar com essa demanda computacional.

Al√©m disso, utilizamos os seguintes recursos/ferramentas:
 - Python
 - Jupyter
 - Pyspark
 - Pandas
 - Matplotlib
 - Seaborn
 - Regex
 - Natural Language Toolkit
 - TextBlob

## üê§ Tweets da Campanha Eleitoral de 2014

### Hashtags e Tweets

#### Hashtags mais usadas pela manh√£, tarde e noite:
Para identificar as hashtags mais usadas pela manh√£, tarde e noite, fazemos uma an√°lise temporal dos tweets, categorizando-os em diferentes per√≠odos do dia (manh√£, tarde e noite) com base no hor√°rio em que foram postados. 

Em seguida, fazemos a contagem das hashtags mais frequentes em cada per√≠odo e os resultados s√£o apresentados em gr√°ficos de barras, mostrando as 10 hashtags mais populares em cada per√≠odo do dia:

#### Hashtags mais usadas em cada dia
A an√°lise das hashtags mais usadas em cada dia √© feita atrav√©s da contagem das hashtags presentes nos tweets de cada dia, agrupadas por data. 

Filtramos os tweets que possuem hashtags, contabilizamos a frequ√™ncia das hashtags em cada dia e apresentamos os resultados em gr√°ficos de barras, exibindo as 10 hashtags mais utilizadas em cada dia:

#### N√∫mero de tweets por hora a cada dia
Calculamos o n√∫mero de tweets por hora em cada dia, agrupando os tweets por hora do dia e contabilizando a quantidade de tweets em cada per√≠odo. 

Em seguida, apresentamos os resultados em um gr√°fico de linha, mostrando a distribui√ß√£o temporal do n√∫mero de tweets ao longo das horas do dia:

### Figuras pol√≠ticas

#### Principais senten√ßas relacionadas √† palavra ‚ÄúDilma‚Äù
Para identificar as principais senten√ßas relacionadas √† palavra "Dilma", carregamos os tweets relacionados √† campanha eleitoral do dataset e filtramos aqueles que cont√™m a palavra-chave "Dilma", ap√≥s isso, realizamos a limpeza e formata√ß√£o dos dados, removendo caracteres especiais e stopwords da l√≠ngua portuguesa. 

Ap√≥s essa etapa, utilizamos a t√©cnica de n-gramas para identificar sequ√™ncias de 3 a 5 palavras mais frequentes nos tweets, selecionando dessas, as 10 express√µes mais comuns:

#### Principais senten√ßas relacionadas √† palavra ‚ÄúA√©cio‚Äù
Utilizamos o mesmo processo para identificarmos as principais senten√ßas relacionadas √† palavra "A√©cio".

Fizemos isso apenas trocando a constante `WORD` que era `dilma` para `aecio`: